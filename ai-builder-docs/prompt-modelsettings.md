---
title: AI Prompt Settings - model selection and Temperature
description: Learn about Settings parameter in Prompt Builder
author: Antoine2F
contributors:
  - Antoine2F
  - v-aangie
ms.topic: conceptual
ms.date: 04/20/2024
ms.author: antode
ms.reviewer: angieandrews
---

#  Prompt Settings 
When creating a custom prompt in Prompt Builder, right hand panel includes a 'Settings' section. 

This section allows to set these parameters:
- Prompt details
- Input
- Data used (preview)
- Output
- Model setting
- Temperature setting

Let's explore the impact of these parameters.

## Prompt details
In this section you can define the **Name** of your prompt. This name will identify your prompt through the different the consumption experiences: Power Automate, Power Apps and Copilot Studio.

## Inputs
Inputs can be added inside a prompt in order to inject data that is not defined yet at prompt creation time but can be known as prediction time. 

Example: The following prompt includes an **Input** called EmailContent that will be passed at prediction time in a Power Automate flow.

:::image type="content" source="media/prompt-settings/prompt-settings-input.png" alt-text="Prompt input":::

It's possible to associate **Sample data** to an **Input** to test the prompt with relevant data.


## Data used (preview)

## Output


## Model setting
### Versions
The dropdown allows to select between the available Generative AI models, which will be used to generate the answer to your custom prompt.

Default model is a GA GPT model. As of May 2024, it is GPT 3.5. Previous Prompts created in Prompt Builder relies on this default model.  
Exact version is GPT 3.5 turbo 0613, and it will switch to GPT 3.5 turbo 0125 model in June timeframe, as GPT 3.5 0613 is getting deprecated.
GPT 3.5 model is consuming AI Builder credits when used in Apps or Flows.

The other available model (as of May 2024) is GPT 4. As long as it's in preview mode, it won't consume AI Builder credits when used in Apps or Flows.  
As a preview model, use is linked to AI Builder preview toggle in environment settings. ([Power Platform Admin Center](https://admin.powerplatform.microsoft.com/environments) -> select Environment -> Settings -> Features)
When preview models are Off, GPT 4 cannot be selected in the dropdown and previously created prompts are blocked.  
Exact version is subject to change.  

### Use of AI Prompts in context of Copilot Studio
AI Prompts don't consume AI Builder credits when in the context of Copilot Studio.
When built using a GA generative AI model (like GPT 3.5), they consume messages.
When built using a Preview generative AI model, they don't consume messages.

**Choice between available models should be based on status, licensing rules and functionalities**

|GPT model  |Status  |Licensing rules  | Functionalities|
|---------|---------|---------|---------|
|GPT 3.5| GA - Default model | Consumes credits in Apps, Flows . See Licensing Guide and Calculator | Trained on data up to Sept 2021. Context allowed up to 16k tokens |
| GPT 4 | Preview | Free | Trained on data up to April 2023. Context allowed up to 128k tokens. Multilingual enhanced proficiency. Better than GPT 3.5 in technical redaction and creativity |

## Temperature setting
The slider allows to select the Temperature of the Generative AI model. It varies between 0 and 1, and guides the Generative AI model about how much creativity (1) vs deterministic answer (0) it should provide.
Temperature is a parameter that controls the randomness of the output generated by the AI model. A lower temperature results in more predictable and conservative outputs, while a higher temperature allows for more creativity and diversity in the responses. It’s a way to fine-tune the balance between randomness and determinism in the model’s output.
By default - and in previously created prompts - Temperature is 0.

|Temperature  |Functionality| Use in|
|---------|---------|---------|
|0| more predictable and conservative outputs<br>responses are more consistent| Prompts requiring high accuracy and less variability|
|1| more creativity and diversity in the responses <br> more varied and sometimes more innovative responses| Prompts creating new out-of-the-box content |

While adjusting the temperature can influence the model’s output, it doesn’t guarantee a specific result, as the AI’s responses are inherently probabilistic and can vary even with the same temperature setting.


